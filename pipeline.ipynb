{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43f0d5ba-9216-4c80-8a3d-0a97de01b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.cloud.aiplatform as aip\n",
    "import kfp\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import pipeline, component, Output, Metrics, Dataset, Input, Model\n",
    "from typing import NamedTuple\n",
    "from src import util, data_preparation, preprocessing, modelling\n",
    "\n",
    "config = util.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3faac162-f62a-461e-96a5-1b57db01128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v01' # Please change so it doesn't replace previous version\n",
    "\n",
    "PIPELINE_ROOT = f'{config[\"BUCKET\"]}/pipelines/{config[\"DATASET_DISPLAY_NAME\"]}'\n",
    "PIPELINE_DISPLAY_NAME = f'{config[\"DATASET_DISPLAY_NAME\"]}-train-pipeline-{VERSION}'\n",
    "MODEL_DIRECTORY = f'{config[\"BUCKET\"]}/models/{config[\"DATASET_DISPLAY_NAME\"]}'\n",
    "MODEL_DISPLAY_NAME = f'{config[\"DATASET_DISPLAY_NAME\"]}-classifier-{VERSION}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "de314f93-4aa5-4355-a01a-d5509412817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"bank-marketing-pipeline-image:latest\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-bigquery',\n",
    "        'google-cloud-storage',\n",
    "        'db-dtypes',\n",
    "        'joblib',\n",
    "        'numpy',\n",
    "        'pandas',\n",
    "        'scikit-learn',\n",
    "        'imblearn'\n",
    "    ]\n",
    ")\n",
    "def data_preparation(\n",
    "    config: dict,\n",
    "    train: Output[Dataset],\n",
    "    valid: Output[Dataset],\n",
    "    test: Output[Dataset]):\n",
    "    \n",
    "    # 1. Load configuration file\n",
    "    config = util.load_config()\n",
    "    \n",
    "    # 2. Read raw dataset\n",
    "    raw_dataset = pd.read_csv(f'{config[\"BUCKET\"]}{config[\"dataset_path\"]}', delimiter=config['dataset_delimiter'])\n",
    "    \n",
    "    # 3. Data defense for non API data\n",
    "    data_preparation.check_data(raw_dataset, config)\n",
    "    \n",
    "    # 4. Splitting train, valid, and test set\n",
    "    X_train, X_valid, X_test, \\\n",
    "       y_train, y_valid, y_test = data_preparation.split_data(raw_dataset, config)\n",
    "    \n",
    "    # 5. Concat train, valid, and test set\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    valid = pd.concat([X_valid, y_valid], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    # Define a dictionary to package the outputs\n",
    "    dataset = {\n",
    "        \"train\": train,\n",
    "        \"valid\": valid,\n",
    "        \"test\": test\n",
    "    }\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "489b4b47-6478-405a-a93c-ebec8e4f812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\n",
    "        'google-cloud-bigquery',\n",
    "        'google-cloud-storage',\n",
    "        'db-dtypes',\n",
    "        'joblib',\n",
    "        'numpy',\n",
    "        'pandas',\n",
    "        'scikit-learn',\n",
    "        'imblearn'\n",
    "    ]\n",
    ")\n",
    "def preprocessing(\n",
    "    config: dict,\n",
    "    train: Input[Dataset],\n",
    "    valid: Input[Dataset],\n",
    "    test: Input[Dataset],\n",
    "    X_train: Output[Dataset], y_train: Output[Dataset],\n",
    "    X_valid: Output[Dataset], y_valid: Output[Dataset],\n",
    "    X_test: Output[Dataset], y_test: Output[Dataset]):\n",
    "    \n",
    "    # 1. Load configuration file\n",
    "    config = util.load_config()\n",
    "    \n",
    "    # 2. Load dataset\n",
    "    train, valid, test = dataset.values()\n",
    "    \n",
    "    # 3. Preprocessing dataset\n",
    "    train_processed = preprocessing.preprocessing(train, is_api=False)\n",
    "    valid_processed = preprocessing.preprocessing(valid, is_api=False)\n",
    "    test_processed = preprocessing.preprocessing(test, is_api=False)\n",
    "    \n",
    "    # 4. Feature engineering\n",
    "    train_processed = preprocessing.feature_engineering(train_processed)\n",
    "    valid_processed = preprocessing.feature_engineering(valid_processed)\n",
    "    test_processed = preprocessing.feature_engineering(test_processed)\n",
    "    \n",
    "    # 5. Split X and y\n",
    "    X_train, y_train = train_processed.drop(columns=config['label']), train_processed[config['label']]\n",
    "    X_valid, y_valid = valid_processed.drop(columns=config['label']), valid_processed[config['label']]\n",
    "    X_test, y_test = test_processed.drop(columns=config['label']), test_processed[config['label']]\n",
    "    \n",
    "    # Define dictionary to package the outputs\n",
    "    processed_dataset = {\n",
    "        \"train\": (X_train, y_train),\n",
    "        \"valid\": (X_valid, y_valid),\n",
    "        \"test\": (X_test, y_test)\n",
    "    }\n",
    "    \n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4b01dda2-2881-4bab-8525-d86bb1b3a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\n",
    "        'google-cloud-bigquery',\n",
    "        'google-cloud-storage',\n",
    "        'db-dtypes',\n",
    "        'joblib',\n",
    "        'numpy',\n",
    "        'pandas',\n",
    "        'scikit-learn',\n",
    "        'imblearn'\n",
    "    ]\n",
    ")\n",
    "def modelling(\n",
    "    config: dict,\n",
    "    X_train: Input[Dataset], y_train: Input[Dataset],\n",
    "    X_valid: Input[Dataset], y_valid: Input[Dataset],\n",
    "    X_test: Input[Dataset], y_test: Input[Dataset],\n",
    "    model: Output[Model]):\n",
    "    \n",
    "    # 1. Load configuration file\n",
    "    config = util.load_config()\n",
    "    \n",
    "    # 2. Load dataset\n",
    "    # X_train, y_train = processed_dataset[\"train\"]\n",
    "    # X_valid, y_valid = processed_dataset[\"valid\"]\n",
    "    # X_test, y_test = processed_dataset[\"test\"]\n",
    "    \n",
    "    # 3. Random under sampling train set\n",
    "    X_rus, y_rus = modelling.rus_fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 4. Train model\n",
    "    model = modelling.train_model(X_rus, y_rus, X_valid, y_valid, X_test, y_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b59d2e61-6fc5-4fd4-be6c-dc75e79bdfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=PIPELINE_DISPLAY_NAME\n",
    ")\n",
    "def pipeline(config: dict):\n",
    "    data_preparation_op = data_preparation(config=config)\n",
    "    \n",
    "    preprocessing_op = preprocessing(config=config,\n",
    "                                     train=data_preparation_op.outputs[\"train\"],\n",
    "                                     valid=data_preparation_op.outputs[\"valid\"],\n",
    "                                     test=data_preparation_op.outputs[\"test\"])\n",
    "    \n",
    "    modelling_op = modelling(config=config, \n",
    "                             x_train=preprocessing_op.outputs[\"X_train\"],\n",
    "                             y_train=preprocessing_op.outputs[\"y_train\"],\n",
    "                             x_valid=preprocessing_op.outputs[\"X_valid\"],\n",
    "                             y_valid=preprocessing_op.outputs[\"y_valid\"],\n",
    "                             x_test=preprocessing_op.outputs[\"X_test\"],\n",
    "                             y_test=preprocessing_op.outputs[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa77096f-a29e-48a7-a280-e9776bca448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path='pipeline.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "75a3930d-167e-41f0-8803-52ce6ff9ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/186470930776/locations/asia-southeast2/pipelineJobs/bank-marketing-train-pipeline-v01-20231008161729\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/186470930776/locations/asia-southeast2/pipelineJobs/bank-marketing-train-pipeline-v01-20231008161729')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-southeast2/pipelines/runs/bank-marketing-train-pipeline-v01-20231008161729?project=186470930776\n"
     ]
    }
   ],
   "source": [
    "job = aip.PipelineJob(\n",
    "    display_name=\"bank-marketing-temp-pipeline\",\n",
    "    template_path='pipeline.json',\n",
    "    parameter_values={\"config\":config},\n",
    "    project = PROJECT,\n",
    "    location= 'asia-southeast2',\n",
    "    enable_caching=False,\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb812940-f933-4fed-8304-6078fbefc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform'\n",
    "    ]\n",
    ")\n",
    "def deploy(config: dict, model):\n",
    "    # 1. Load configuration file\n",
    "    config = util.load_config()\n",
    "    \n",
    "    # 2. Initialization\n",
    "    project = config[\"PROJECT\"]\n",
    "    region = config[\"REGION\"]\n",
    "    aip.init(project=project, location=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bde2e-63fc-4f36-9526-cbb9a7af7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyyaml\n",
    "joblib\n",
    "pandas\n",
    "scikit-learn\n",
    "imbalanced-learn\n",
    "typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "27be08c2-5230-4bf6-a939-b4dabb2ebaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.4.1'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "yaml.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5b8a45bf-718c-4448-ae2c-86f5a2402e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -bsl-py (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (5.4.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -bsl-py (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7a5f4b36-1195-425e-9499-218879d5bfb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2172178/1999820834.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparameter_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPROJECT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'asia-southeast2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, display_name, template_path, job_id, pipeline_root, parameter_values, input_artifacts, enable_caching, encryption_spec_key_name, labels, credentials, project, location, failure_policy)\u001b[0m\n\u001b[1;32m    247\u001b[0m         )\n\u001b[1;32m    248\u001b[0m         builder = pipeline_utils.PipelineRuntimeConfigBuilder.from_job_spec_json(\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mpipeline_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    251\u001b[0m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pipeline_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/utils/pipeline_utils.py\u001b[0m in \u001b[0;36mfrom_job_spec_json\u001b[0;34m(cls, job_spec)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mruntime_config_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"runtimeConfig\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         parameter_input_definitions = (\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mjob_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pipelineSpec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputDefinitions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'root'"
     ]
    }
   ],
   "source": [
    "job = aip.PipelineJob(\n",
    "    display_name=\"bank-marketing-pipeline-test\",\n",
    "    template_path=os.path.abspath(\"my-pipeline.yaml\"),\n",
    "    parameter_values={\"config\":config},\n",
    "    project = PROJECT,\n",
    "    location= 'asia-southeast2'\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6287a511-4350-4abb-a2ab-0ac9ae92c5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/carlo/bank-marketing/my-pipeline.yaml'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(\"my-pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b2368-d614-4e54-81fe-8e1575fea497",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipeline_job = aip.PipelineJob(\n",
    "    display_name=\"bank-marketing-pipeline-test\",\n",
    "    template_path=\"my-pipeline.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    location=PROJECT_REGION,\n",
    "    parameter_values={\"project\": PROJECT_ID, \"display_name\": PIPELINE_DISPLAY_NAME},\n",
    "    enable_caching=True\n",
    ")\n",
    "\n",
    "ml_pipeline_job.submit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c6e6bbfc-81a8-44c2-9e14-5717dafa2b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://adi-mlops-bucket/pipelines/bank-marketing'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPELINE_ROOT"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
